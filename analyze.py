import os
import requests
import json
import re
import base64
from supabase import create_client

# ç’°å¢ƒå¤‰æ•°
SB_URL = os.environ.get("SUPABASE_URL")
SB_KEY = os.environ.get("SUPABASE_ANON_KEY")
GEMINI_KEY = os.environ.get("GEMINI_API_KEY")

supabase = create_client(SB_URL, SB_KEY)

def extract_json(text):
    try:
        match = re.search(r'\{.*\}', text, re.DOTALL)
        return json.loads(match.group()) if match else None
    except:
        return None

def analyze_and_filter(limit=5):
    res = supabase.table("YouTubeMV_Japanese") \
        .select("video_id, thumbnail_url, title, channel_title") \
        .eq("is_analyzed", False) \
        .order("view_count", desc=True) \
        .limit(limit) \
        .execute()

    videos = res.data
    if not videos:
        print("âœ… è§£æå¾…ã¡ã®å‹•ç”»ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã€é‡è¦ã€‘404ã‚’å›é¿ã™ã‚‹å”¯ä¸€ã®URLæ§‹é€ 
    # ãƒ¢ãƒ‡ãƒ«åã‚’URLã®æœ«å°¾ã§ã¯ãªãã€ãƒ‘ã‚¹ã®é€”ä¸­ã«å«ã‚ã‚‹å½¢å¼ã§ã™
    api_url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_KEY}"

    for v in videos:
        print(f"ğŸ§ åˆ¤å®šãƒ»è§£æä¸­: {v['title']}")
        try:
            img_data = base64.b64encode(requests.get(v['thumbnail_url']).content).decode('utf-8')
            
            payload = {
                "contents": [{
                    "parts": [
                        {"text": f"å‹•ç”»: {v['title']}\nå…¬å¼MVãªã‚‰ trueã€é•ã†ãªã‚‰ falseã€‚JSON: {{\"is_official\": boolean}}"},
                        {"inline_data": {"mime_type": "image/jpeg", "data": img_data}}
                    ]
                }]
            }

            response = requests.post(api_url, json=payload, headers={'Content-Type': 'application/json'})
            resp_json = response.json()

            if 'error' in resp_json:
                # ã“ã“ã§ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹å ´åˆã€ã‚­ãƒ¼ã®ã€Œãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€ãŒãã‚‚ãã‚‚ç„¡åŠ¹ã§ã™
                print(f"  âŒ APIã‚¨ãƒ©ãƒ¼: {resp_json['error']['message']}")
                continue

            ai_text = resp_json['candidates'][0]['content']['parts'][0]['text']
            result = extract_json(ai_text)

            if result:
                supabase.table("YouTubeMV_Japanese").update({
                    "is_official_mv": result.get("is_official", True),
                    "is_analyzed": True
                }).eq("video_id", v['video_id']).execute()
                print(f"  > åˆ¤å®šæˆåŠŸ!")
            else:
                print(f"  âš ï¸ è§£æå¤±æ•—")

        except Exception as e:
            print(f"  âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

if __name__ == "__main__":
    analyze_and_filter(5)
