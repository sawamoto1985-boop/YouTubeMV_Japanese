import os
import requests
import json
import base64
import re
from supabase import create_client

# ç’°å¢ƒå¤‰æ•°
SB_URL = os.environ.get("SUPABASE_URL")
SB_KEY = os.environ.get("SUPABASE_ANON_KEY")
GEMINI_KEY = os.environ.get("GEMINI_API_KEY")

# SupabaseåˆæœŸåŒ–
supabase = create_client(SB_URL, SB_KEY)

def extract_json(text):
    try:
        match = re.search(r'\{.*\}', text, re.DOTALL)
        return json.loads(match.group()) if match else None
    except:
        return None

def analyze_and_filter(limit=5):
    print(f"ğŸ“‹ æœªè§£æã®å‹•ç”»ã‚’ {limit} ä»¶å–å¾—ã—ã¾ã™...")
    res = supabase.table("YouTubeMV_Japanese") \
        .select("video_id, thumbnail_url, title, channel_title") \
        .eq("is_analyzed", False) \
        .order("view_count", desc=True) \
        .limit(limit) \
        .execute()

    videos = res.data
    if not videos:
        print("âœ… è§£æå¾…ã¡ã®å‹•ç”»ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã€é‡è¦ã€‘ãƒªã‚¹ãƒˆã«ã‚ã£ãŸæœ€æ–°ãƒ¢ãƒ‡ãƒ«ã€Œgemini-2.5-flashã€ã‚’æŒ‡å®š
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={GEMINI_KEY}"
    headers = {'Content-Type': 'application/json'}

    for v in videos:
        print(f"ğŸ§ è§£æä¸­: {v['title']}")
        
        try:
            # ç”»åƒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ & Base64å¤‰æ›
            img_data = requests.get(v['thumbnail_url']).content
            b64_img = base64.b64encode(img_data).decode('utf-8')

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            prompt = (
                f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {v['title']}\n"
                f"ãƒãƒ£ãƒ³ãƒãƒ«å: {v['channel_title']}\n\n"
                "æŒ‡ç¤º:\n"
                "ã“ã®å‹•ç”»ã¯ã€Œã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå…¬å¼ã®Music Videoã€ã§ã™ã‹ï¼Ÿ\n"
                "Liveæ˜ åƒã€æ­Œã£ã¦ã¿ãŸã€åˆ‡ã‚ŠæŠœãã€ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³å‹•ç”»ã¯ false ã«ã—ã¦ãã ã•ã„ã€‚\n"
                "å›ç­”ã¯ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
                "{\"is_official\": boolean, \"reason\": \"ç†ç”±ã‚’çŸ­ã\", \"tags\": [\"#é›°å›²æ°—ã‚¿ã‚°1\", \"#ã‚¿ã‚°2\"]}"
            )

            # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            payload = {
                "contents": [{
                    "parts": [
                        {"text": prompt},
                        {"inline_data": {"mime_type": "image/jpeg", "data": b64_img}}
                    ]
                }]
            }

            # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = requests.post(url, headers=headers, json=payload)
            result = response.json()

            if "error" in result:
                print(f"  âŒ APIã‚¨ãƒ©ãƒ¼: {result['error']['message']}")
                continue

            # çµæœä¿å­˜
            ai_text = result['candidates'][0]['content']['parts'][0]['text']
            json_data = extract_json(ai_text)
            
            if json_data:
                is_official = json_data.get("is_official", False)
                tags = json_data.get("tags", [])
                
                supabase.table("YouTubeMV_Japanese").update({
                    "is_official_mv": is_official,
                    "ai_tags": tags,
                    "is_analyzed": True
                }).eq("video_id", v['video_id']).execute()

                print(f"  > åˆ¤å®š: {'âœ… å…¬å¼' if is_official else 'âŒ å¯¾è±¡å¤–'}")
            else:
                print(f"  âš ï¸ JSONè§£æå¤±æ•—: {ai_text[:50]}...")

        except Exception as e:
            print(f"  âš ï¸ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    analyze_and_filter(5)
