import os
import time
import re
from googleapiclient.discovery import build
from supabase import create_client

# ç’°å¢ƒå¤‰æ•°
YT_API_KEY = os.environ.get("YOUTUBE_API_KEY")
SB_URL = os.environ.get("SUPABASE_URL")
SB_KEY = os.environ.get("SUPABASE_ANON_KEY")

supabase = create_client(SB_URL, SB_KEY)
youtube = build('youtube', 'v3', developerKey=YT_API_KEY)

def is_japanese(text):
    if not text: return False
    return bool(re.search(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¥]', text))

def get_video_stats(video_ids):
    res = youtube.videos().list(part="statistics", id=",".join(video_ids)).execute()
    return {item['id']: int(item['statistics'].get('viewCount', 0)) for item in res.get('items', [])}

def fetch_and_save_mvs(target_count=1000):
    collected_data = []
    next_page_token = None
    search_query = 'official music video | "MV" | "ãƒŸãƒ¥ãƒ¼ã‚¸ãƒƒã‚¯ãƒ“ãƒ‡ã‚ª"'
    
    print(f"ğŸš€ 1000ä»¶ã®é‚¦æ¥½MVåé›†ã‚’é–‹å§‹ã—ã¾ã™")

    # ç›®æ¨™ã«é”ã™ã‚‹ã¾ã§æœ€å¤§50å›ãƒ«ãƒ¼ãƒ—ï¼ˆ1å›50ä»¶å–å¾—ï¼‰
    for i in range(50): 
        if len(collected_data) >= target_count:
            break

        search_res = youtube.search().list(
            q=search_query,
            part="snippet", type="video", regionCode="JP",
            relevanceLanguage="ja", order="date", maxResults=50,
            pageToken=next_page_token
        ).execute()

        video_ids = [item['id']['videoId'] for item in search_res.get('items', [])]
        if not video_ids: break
        
        stats_dict = get_video_stats(video_ids)

        for item in search_res.get('items', []):
            v_id = item['id']['videoId']
            snippet = item['snippet']
            title, desc, channel = snippet['title'], snippet['description'], snippet['channelTitle']
            
            # æ—¥æœ¬èªãƒ•ã‚£ãƒ«ã‚¿
            if not (is_japanese(title) or is_japanese(desc) or is_japanese(channel)):
                continue

            collected_data.append({
                "video_id": v_id,
                "title": title,
                "description": desc,
                "thumbnail_url": snippet['thumbnails']['high']['url'],
                "published_at": snippet['publishedAt'],
                "channel_title": channel,
                "view_count": stats_dict.get(v_id, 0),
                "is_analyzed": False
            })
            if len(collected_data) >= target_count: break

        next_page_token = search_res.get('nextPageToken')
        print(f"ğŸ“ˆ é€²æ—: {len(collected_data)} / {target_count} (Loop: {i+1})")
        if not next_page_token: break
        time.sleep(0.2) # è² è·è»½æ¸›

    # Supabaseã¸ä¸€æ‹¬ä¿å­˜
    if collected_data:
        for i in range(0, len(collected_data), 100):
            batch = collected_data[i:i+100]
            supabase.table("YouTubeMV_Japanese").upsert(batch).execute()
        print(f"âœ¨ å®Œäº†: åˆè¨ˆ {len(collected_data)} ä»¶ã‚’åŒæœŸã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    fetch_and_save_mvs(1000)
