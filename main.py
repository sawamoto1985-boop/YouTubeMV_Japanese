import os
import time
from datetime import datetime
from googleapiclient.discovery import build
from supabase import create_client

# --- è¨­å®š ---
YOUTUBE_API_KEY = os.environ.get("YOUTUBE_API_KEY")
SB_URL = os.environ.get("SUPABASE_URL")
SB_KEY = os.environ.get("SUPABASE_ANON_KEY")

youtube = build("youtube", "v3", developerKey=YOUTUBE_API_KEY)
supabase = create_client(SB_URL, SB_KEY)

def fetch_yearly_mvs(year, count_limit=100):
    print(f"ğŸ“… {year}å¹´ã®MVã‚’åé›†ã—ã¦ã„ã¾ã™...")
    
    start_time = f"{year}-01-01T00:00:00Z"
    end_time = f"{year}-12-31T23:59:59Z"
    
    # é™¤å¤–ãƒ¯ãƒ¼ãƒ‰ã‚’å¾¹åº•ã—ã¦ç²¾åº¦ã‚’ä¸Šã’ã‚‹
    query = "official MV -cover -æ­Œã£ã¦ã¿ãŸ -reaction -åˆ‡ã‚ŠæŠœã -LIVE -ã‚«ãƒ©ã‚ªã‚±"
    
    videos = []
    next_page_token = None
    
    # 50ä»¶ãšã¤ã€æœ€å¤§2å›ãƒ«ãƒ¼ãƒ—ï¼ˆåˆè¨ˆ100ä»¶ï¼‰
    while len(videos) < count_limit:
        search_response = youtube.search().list(
            q=query,
            part="snippet",
            maxResults=min(50, count_limit - len(videos)),
            type="video",
            videoCategoryId="10",      # Musicã‚«ãƒ†ã‚´ãƒªå›ºå®š
            relevanceLanguage="ja",    # æ—¥æœ¬èª
            regionCode="JP",           # æ—¥æœ¬
            publishedAfter=start_time,
            publishedBefore=end_time,
            order="viewCount",         # å†ç”Ÿæ•°é †
            pageToken=next_page_token
        ).execute()
        
        for item in search_response['items']:
            v_id = item['id']['videoId']
            snippet = item['snippet']
            
            videos.append({
                "video_id": v_id,
                "title": snippet['title'],
                "channel_title": snippet['channelTitle'],
                "thumbnail_url": snippet['thumbnails']['high']['url'],
                "published_at": snippet['publishedAt'],
                "view_count": 0, # å¾Œã§æ›´æ–°ã™ã‚‹ã‹ã€ã¨ã‚Šã‚ãˆãš0
                "is_analyzed": False # ã“ã‚ŒãŒé‡è¦ï¼ˆGeminiåˆ¤å®šã«å›ã™ãŸã‚ï¼‰
            })
            
        next_page_token = search_response.get('nextPageToken')
        if not next_page_token:
            break
            
    return videos

def save_to_supabase(videos):
    new_count = 0
    for v in videos:
        # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆvideo_idãŒæ—¢ã«ã‚ã‚‹ã‹ï¼‰
        check = supabase.table("YouTubeMV_Japanese").select("video_id").eq("video_id", v["video_id"]).execute()
        
        if not check.data:
            supabase.table("YouTubeMV_Japanese").insert(v).execute()
            new_count += 1
            
    print(f"  âœ… {new_count} ä»¶ã®æ–°ã—ã„å‹•ç”»ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    current_year = datetime.now().year
    # 2011å¹´ï¼ˆ15å¹´å‰ï¼‰ã‹ã‚‰ä»Šå¹´ã¾ã§ãƒ«ãƒ¼ãƒ—
    for year in range(2011, current_year + 1):
        try:
            yearly_videos = fetch_yearly_mvs(year, 100)
            save_to_supabase(yearly_videos)
            time.sleep(2) # APIåˆ¶é™ã«å„ªã—ã
        except Exception as e:
            print(f"  âŒ {year}å¹´ã®åé›†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    print("\nğŸ‰ å…¨å¹´ä»£ã®åé›†ä½œæ¥­ãŒå®Œäº†ã—ã¾ã—ãŸï¼æ¬¡ã¯ analyze.py ã‚’å‹•ã‹ã—ã¦AIåˆ¤å®šã‚’ã—ã¦ãã ã•ã„ã€‚")
